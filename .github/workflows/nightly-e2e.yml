name: Nightly E2E Tests

on:
  schedule:
    # Run every night at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      baseline_update:
        description: 'Update performance baselines'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHONPATH: src

jobs:
  nightly-e2e:
    name: Nightly E2E Test Suite
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v5

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y lxc lxc-utils lxc-templates bridge-utils postgresql redis-server supervisor

    - name: Configure LXC for E2E
      run: |
        sudo systemctl start lxc-net
        sudo usermod -aG lxc $USER
        echo "LXC capabilities configured for nightly E2E tests"

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-xdist psutil

    - name: Create performance baseline directory
      run: mkdir -p performance_baselines

    # E2E tests disabled - using legacy tests only
    # - name: Run E2E tests with comprehensive monitoring
    #   run: |
    #     echo "Starting comprehensive E2E test suite at $(date)"
    #     sudo -E pytest tests/e2e/ --run-e2e -v --tb=short --performance-monitoring --baseline-compare --maxfail=5

    - name: Generate performance baseline (if requested)
      if: github.event.inputs.baseline_update == 'true'
      run: |
        echo "Updating performance baselines..."
        python -m tests.e2e.utilities.baseline_collector --scenario data_pipeline --duration 60
        python -m tests.e2e.utilities.baseline_collector --scenario automation_workflows --duration 60
        python -m tests.e2e.utilities.baseline_collector --scenario error_handling --duration 60

    - name: Analyze test logs
      if: always()
      run: |
        python -m tests.e2e.utilities.log_analyzer --log-files e2e_test.log --output log_analysis_report.json --summary-only

    - name: Upload E2E test artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: nightly-e2e-artifacts-${{ github.run_number }}
        path: |
          performance_reports/
          performance_baselines/
          e2e_test.log
          log_analysis_report.json
          **/*.log
          **/*_performance.json
          **/*_regressions.txt
          **/*_comparison.json
        retention-days: 90

    - name: Generate nightly summary report
      if: always()
      run: |
        echo "# Nightly E2E Test Report" > nightly_report.md
        echo "- Date: $(date)" >> nightly_report.md
        echo "- Commit: ${{ github.sha }}" >> nightly_report.md
        echo "- Branch: ${{ github.ref_name }}" >> nightly_report.md
        echo "- Run: ${{ github.run_id }}" >> nightly_report.md
        echo "" >> nightly_report.md

        if [ -d performance_reports ]; then
          echo "## Performance Metrics" >> nightly_report.md
          echo "- Reports generated: $(ls performance_reports/ | wc -l)" >> nightly_report.md
          echo "- Regressions detected: $(find performance_reports -name "*regressions.txt" | wc -l)" >> nightly_report.md
          echo "" >> nightly_report.md
        fi

        if [ -f log_analysis_report.json ]; then
          echo "## Log Analysis" >> nightly_report.md
          echo "- Analysis completed: $(date -r log_analysis_report.json)" >> nightly_report.md
          echo "" >> nightly_report.md
        fi

        echo "## Test Status" >> nightly_report.md
        if [ -f e2e_test.log ]; then
          echo "- Test log size: $(du -h e2e_test.log | cut -f1)" >> nightly_report.md
          echo "- Errors found: $(grep -c "ERROR\|FAILED\|error\|failed" e2e_test.log || echo "0")" >> nightly_report.md
        fi

    - name: Upload nightly report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: nightly-e2e-report-${{ github.run_number }}
        path: nightly_report.md

    - name: Notify on failures
      if: failure()
      run: |
        echo "❌ Nightly E2E tests failed"
        echo "Check the artifacts for detailed logs and performance reports"
        # In a real scenario, this could send notifications to Slack/Discord/etc

    - name: Notify on regressions
      if: always()
      run: |
        if [ -n "$(find performance_reports -name "*regressions.txt" 2>/dev/null)" ]; then
          echo "⚠️ Performance regressions detected!"
          echo "Review the performance artifacts for details"
          # Could trigger alerts for performance degradation
        else
          echo "✅ No performance regressions detected"
        fi
